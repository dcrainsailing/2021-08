{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "respective-yugoslavia",
   "metadata": {},
   "source": [
    "1.【练习】定义X,Y的联合熵为H(Y,X)为E(Y,X)∼p(y,x)[−log2p(Y,X)]\n",
    "\n",
    "    请证明如下关系： G(Y,X)=H(X)−H(X|Y)\n",
    "\n",
    "G(Y,X)=H(X)+H(Y)−H(Y,X) G(Y,X)=H(Y,X)−H(X|Y)−H(Y|X)\n",
    "\n",
    "下图被分为了A、B和C三个区域。若AB区域代表X的不确定性，BC区域代表Y的不确定性，那么H(X)\n",
    "、H(Y)、H(X|Y)、H(Y|X)、H(X,Y)和G(X,Y)\n",
    "\n",
    "    分别指代的是哪片区域？\n",
    "    \n",
    "    \n",
    "![](_images/tree_pic3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-contributor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "roman-crowd",
   "metadata": {},
   "source": [
    "2.【练习】假设当前我们需要处理一个分类问题，请问对输入特征进行归一化会对树模型的类别输出产生影响吗？请解释原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-degree",
   "metadata": {},
   "source": [
    "因为数值缩放不影响分裂点位置，对树模型的结构不造成影响。\n",
    "\n",
    "没有考虑变量之间相关性，每次筛选都只考虑一个变量（因此不需要归一化）；\n",
    "对于有权重的模型，Feature可以Scaling 比如：线性回归、SVM、(BP？？)对于没有权重的方法，特征不适合做归一化（标准化）如果对特征做了Feature Scaling 那么 可以结合回归的算法，在特征前加上权重。\n",
    "对于线性模型，特征值差别很大时，比如说LR，我有两个特征，一个是(0,1)的，一个是(0,10000)的，运用梯度下降的时候，损失等高线是椭圆形，需要进行多次迭代才能到达最优点。但是如果进行了归一化，那么等高线就是圆形的，促使SGD往原点迭代，从而导致需要的迭代次数较少。所以说是因为梯度下降的算法需要进行归一化，归一化后加快了梯度下降求解最优解的速度。\n",
    "树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，可以看下决策树ID3算法python实现理解。因为求导没意义，也就不需要归一化\n",
    "概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率。像svm、线性回归之类的最优化问题就需要归一化。决策树属于前者。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-brief",
   "metadata": {},
   "source": [
    "3.【练习】如果将系数替换为1−γ2，请问对缺失值是加强了还是削弱了惩罚？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-hello",
   "metadata": {},
   "source": [
    "G~(Y,X)=(1−γ)G(Y~,X~) 替换为1−γ2 时 削弱了惩罚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-journal",
   "metadata": {},
   "source": [
    "4.【练习】如果将树的生长策略从深度优先生长改为广度优先生长，假设其他参数保持不变的情况下，两个模型对应的结果输出可能不同吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-finding",
   "metadata": {},
   "source": [
    "深度优先生长采用深度优先搜索的方法：若当前节点存在未搜索过的子节点，则当前节点跳转到子节点进行分裂决策；\n",
    "若当前节点为叶节点，则调转到上一层节点，直到根节点不存在未搜索过的子节点为止。\n",
    "对上图而言，当前节点为2号，它的两个子节点4号和5号都没有被搜索过，因此下一步则选择两个节点中的一个进行跳转。\n",
    "当决策树使用最佳增益生长时，每次总是选择会带来最大相对信息增益的节点进行分裂，直到叶节点的最大数量达到max_left_nodes。\n",
    "\n",
    "所以：如果将树的生长策略从深度优先生长改为广度优先生长，假设其他参数保持不变的情况下，两个模型对应的结果输出可能不同"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-administration",
   "metadata": {},
   "source": [
    "5.【练习】在一般的机器学习问题中，我们总是通过一组参数来定义模型的损失函数，并且在训练集上以最小化该损失函数为目标进行优化。请问对于决策树而言，模型优化的目标是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-fiction",
   "metadata": {},
   "source": [
    "防止过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-seattle",
   "metadata": {},
   "source": [
    "6.【练习】对信息熵中的log函数在p=1处进行一阶泰勒展开可以近似为基尼系数，那么如果在p=1处进行二阶泰勒展开我们可以获得什么近似指标？请写出对应指标的信息增益公式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-tobago",
   "metadata": {},
   "source": [
    "![](_images/gini.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-plasma",
   "metadata": {},
   "source": [
    "7.【练习】除了信息熵和基尼系数之外，我们还可以使用节点的1−maxkp(Y=yk)和第m个子节点的1−maxkp(Y=yk|X=xm)来作为衡量纯度的指标。请解释其合理性并给出相应的信息增益和加权信息增益公式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-radar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "collective-tunnel",
   "metadata": {},
   "source": [
    "8.【练习】为什么对没有重复特征值的数据，决策树能够做到损失为0？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-brand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "classical-librarian",
   "metadata": {},
   "source": [
    "9.【练习】如何理解min_samples_leaf参数能够控制回归树输出值的平滑程度？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-madrid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 图像分割/二值化\n",
    "\n",
    "## 5.1 简介 \n",
    "该部分的学习内容是对经典的阈值分割算法进行回顾，图像阈值化分割是一种传统的最常用的图像分割方法，因其实现简单、计算量小、性能较稳定而成为图像分割中最基本和应用最广泛的分割技术。它特别适用于目标和背景占据不同灰度级范围的图像。它不仅可以极大的压缩数据量，而且也大大简化了分析和处理步骤，因此在很多情况下，是进行图像分析、特征提取与模式识别之前的必要的图像预处理过程。图像阈值化的目的是要按照灰度级，对像素集合进行一个划分，得到的每个子集形成一个与现实景物相对应的区域，各个区域内部具有一致的属性，而相邻区域不具有这种一致属性。这样的划分可以通过从灰度级出发选取一个或多个阈值来实现。\n",
    "\n",
    "\n",
    "## 5.2 学习目标\n",
    "* 了解阈值分割基本概念\n",
    "\n",
    "* 理解最大类间方差法（大津法）、自适应阈值分割的原理\n",
    "\n",
    "* 掌握OpenCV框架下上述阈值分割算法API的使用\n",
    "\n",
    "\n",
    "## 5.3 内容介绍\n",
    "\n",
    "1、最大类间方差法、自适应阈值分割的原理\n",
    "\n",
    "2、OpenCV代码实践\n",
    "\n",
    "3、动手实践并打卡（读者完成）\n",
    "\n",
    "## 5.4 算法理论介绍\n",
    "### 5.4.1 最大类间方差法（大津阈值法） \n",
    "大津法（OTSU）是一种确定图像二值化分割阈值的算法，由日本学者大津于1979年提出。从大津法的原理上来讲，该方法又称作最大类间方差法，因为按照大津法求得的阈值进行图像二值化分割后，前景与背景图像的类间方差最大。\n",
    "\n",
    "它被认为是图像分割中阈值选取的最佳算法，计算简单，不受图像亮度和对比度的影响，因此在数字图像处理上得到了广泛的应用。它是按图像的灰度特性，将图像分成背景和前景两部分。因方差是灰度分布均匀性的一种度量,背景和前景之间的类间方差越大,说明构成图像的两部分的差别越大,当部分前景错分为背景或部分背景错分为前景都会导致两部分差别变小。因此,使类间方差最大的分割意味着错分概率最小。\n",
    "\n",
    "**应用：** 是求图像全局阈值的最佳方法，应用不言而喻，适用于大部分需要求图像全局阈值的场合。\n",
    "\n",
    "**优点：** 计算简单快速，不受图像亮度和对比度的影响。\n",
    "\n",
    "**缺点：** 对图像噪声敏感；只能针对单一目标分割；当目标和背景大小比例悬殊、类间方差函数可能呈现双峰或者多峰，这个时候效果不好。\n",
    "\n",
    "原理非常简单，涉及的知识点就是均值、方差等概念和一些公式推导。为了便于理解，我们从目的入手，反推一下这著名的OTSU算法。\n",
    "\n",
    "求类间方差：\n",
    "\n",
    "OTSU算法的假设是存在阈值TH将图像所有像素分为两类C1(小于TH)和C2(大于TH)，则这两类像素各自的均值就为m1、m2，图像全局均值为mG。同时像素被分为C1和C2类的概率分别为p1、p2。因此就有：\n",
    "\n",
    "<div align=center><img   src =\"https://img-blog.csdnimg.cn/20200412211054156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDY0NzgxOQ==,size_16,color_FFFFFF,t_70\"/></div>           \n",
    "\n",
    "根据原文，式（4）还可以进一步变形：\n",
    "\n",
    " <div align=center><img   src =\"https://img-blog.csdnimg.cn/20200412210949765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDY0NzgxOQ==,size_16,color_FFFFFF,t_70\"/></div>      \n",
    "\n",
    "分割：\n",
    "\n",
    "这个分割就是二值化，OpenCV给了以下几种方式，很简单，可以参考：\n",
    "\n",
    "!<div align=center><img   src =\"https://img-blog.csdnimg.cn/20200412211203976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDY0NzgxOQ==,size_16,color_FFFFFF,t_70\"/></div>  \n",
    "     \n",
    "\n",
    "### 5.4.2 自适应阈值\n",
    "前面介绍了OTSU算法，但这算法属于全局阈值法，所以对于某些光照不均的图像，这种全局阈值分割的方法会显得苍白无力，如下图：\n",
    "\n",
    "<div align=center><img   src =\"https://img-blog.csdnimg.cn/20200412211750915.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDY0NzgxOQ==,size_16,color_FFFFFF,t_70\"/></div>  \n",
    "\n",
    "显然，这样的阈值处理结果不是我们想要的，那么就需要一种方法来应对这样的情况。\n",
    "\n",
    "这种办法就是自适应阈值法(adaptiveThreshold)，它的思想不是计算全局图像的阈值，而是根据图像不同区域亮度分布，计算其局部阈值，所以对于图像不同区域，能够自适应计算不同的阈值，因此被称为自适应阈值法。(其实就是局部阈值法)\n",
    "\n",
    "如何确定局部阈值呢？可以计算某个邻域(局部)的均值、中值、高斯加权平均(高斯滤波)来确定阈值。值得说明的是：如果用局部的均值作为局部的阈值，就是常说的移动平均法。\n",
    "\n",
    "\n",
    "## 5.5 基于OpenCV的实现\n",
    "\n",
    "* 工具：OpenCV3.1.0+VS2013\n",
    "* 平台：WIN10\n",
    "###  函数原型（c++）\n",
    "**1.最大类间方差法**\n",
    "\n",
    "```cpp\n",
    "double cv::threshold\t(\tInputArray \tsrc,\n",
    "                           OutputArray \tdst,\n",
    "                             double \tthresh,\n",
    "                             double \tmaxval,\n",
    "                               int      type \n",
    ")\t\t\n",
    "```\n",
    "参数：\n",
    "\n",
    "* src —\tinput array (single-channel, 8-bit or 32-bit floating point).\n",
    "* dst\t—   output array of the same size and type as src.\n",
    "* thresh —\t threshold value.\n",
    "* maxval   —\tmaximum value to use with the THRESH_BINARY and THRESH_BINARY_INV thresholding types.\n",
    "* type\t— thresholding type 参考：[thresholdType](https://docs.opencv.org/3.1.0/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3)\n",
    "\n",
    "**1.自适应阈值**\n",
    "```cpp\n",
    "void adaptiveThreshold(InputArray src, OutputArray dst, \n",
    "                             double maxValue,\n",
    "                             int adaptiveMethod,\n",
    "                             int thresholdType, \n",
    "                             int blockSize, double C)\n",
    "```\n",
    "参数：\n",
    "Parameters\n",
    "* src —\tSource 8-bit single-channel image.\n",
    "* dst\t— Destination image of the same size and the same type as src.\n",
    "* maxValue —\tNon-zero value assigned to the pixels for which the condition is satisfied\n",
    "* adaptiveMethod\t— Adaptive thresholding algorithm to use,参考：[cv::AdaptiveThresholdTypes](https://docs.opencv.org/3.1.0/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3)\n",
    "* thresholdType — Thresholding type that must be either THRESH_BINARY or THRESH_BINARY_INV, 可参考：[thresholdType](https://docs.opencv.org/3.1.0/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3)\n",
    "  blockSize\tSize of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on.\n",
    "* C\t— Constant subtracted from the mean or weighted mean (see the details below). Normally, it is positive but may be zero or negative as well.\n",
    "\n",
    "### 实现示例（c++)\n",
    "* 1、大津阈值\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <opencv2/opencv.hpp>\n",
    "using namespace std;\n",
    "using namespace cv;\n",
    " \n",
    "int main(int argc, char* argv[])\n",
    "{\n",
    "\tMat img = imread(argv[1], -1);\n",
    "\tif (img.empty())\n",
    "\t{\n",
    "\t\tcout <<\"Error: Could not load image\" <<endl;\n",
    "\t\treturn 0;\n",
    "\t}\n",
    " \n",
    "\tMat gray;\n",
    "\tcvtColor(img, gray, CV_BGR2GRAY);\n",
    " \n",
    "\tMat dst;\n",
    "\tthreshold(gray, dst, 0, 255, CV_THRESH_OTSU);\n",
    " \n",
    "\timshow(\"src\", img);\n",
    "\timshow(\"gray\", gray);\n",
    "\timshow(\"dst\", dst);\n",
    "\twaitKey(0);\n",
    " \n",
    "\treturn 0;\n",
    "}\n",
    "```\n",
    "* 2、自适应阈值\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <opencv2/opencv.hpp>\n",
    "using namespace std;\n",
    "using namespace cv;\n",
    " \n",
    "int main(int argc, char* argv[])\n",
    "{\n",
    "\tMat img = imread(argv[1], -1);\n",
    "\tif (img.empty())\n",
    "\t{\n",
    "\t\tcout <<\"Error: Could not load image\" <<endl;\n",
    "\t\treturn 0;\n",
    "\t}\n",
    " \n",
    "\tMat gray;\n",
    "\tcvtColor(img, gray, CV_BGR2GRAY);\n",
    " \n",
    "\tMat dst;\n",
    "\tcv::adaptiveThreshold(gray,, dst, 255, cv::ADAPTIVE_THRESH_MEAN_C, cv::THRESH_BINARY, 21, 10);;\n",
    " \n",
    "\timshow(\"src\", img);\n",
    "\timshow(\"gray\", gray);\n",
    "\timshow(\"dst\", dst);\n",
    "\twaitKey(0);\n",
    " \n",
    "\treturn 0;\n",
    "}\n",
    "```\n",
    "\n",
    "### 进阶实现(根据原理自己实现)\n",
    "### 实现示例（c++)\n",
    "* 1、大津阈值\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <opencv2/core.hpp>\n",
    "#include <opencv2/highgui.hpp>\n",
    "#include <opencv2/imgproc.hpp>\n",
    " \n",
    "int Otsu(cv::Mat& src, cv::Mat& dst, int thresh){\n",
    "\tconst int Grayscale = 256;\n",
    "\tint graynum[Grayscale] = { 0 };\n",
    "\tint r = src.rows;\n",
    "\tint c = src.cols;\n",
    "\tfor (int i = 0; i < r; ++i){\n",
    "\t\tconst uchar* ptr = src.ptr<uchar>(i);\n",
    "\t\tfor (int j = 0; j < c; ++j){        //直方图统计\n",
    "\t\t\tgraynum[ptr[j]]++;\n",
    "\t\t}\n",
    "\t}\n",
    " \n",
    "    double P[Grayscale] = { 0 };   \n",
    "\tdouble PK[Grayscale] = { 0 };\n",
    "\tdouble MK[Grayscale] = { 0 };\n",
    "\tdouble srcpixnum = r*c, sumtmpPK = 0, sumtmpMK = 0;\n",
    "\tfor (int i = 0; i < Grayscale; ++i){\n",
    "\t\tP[i] = graynum[i] / srcpixnum;   //每个灰度级出现的概率\n",
    "\t\tPK[i] = sumtmpPK + P[i];         //概率累计和 \n",
    "\t\tsumtmpPK = PK[i];\n",
    "\t\tMK[i] = sumtmpMK + i*P[i];       //灰度级的累加均值                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "\t\tsumtmpMK = MK[i];\n",
    "\t}\n",
    "\t\n",
    "\t//计算类间方差\n",
    "\tdouble Var=0;\n",
    "\tfor (int k = 0; k < Grayscale; ++k){\n",
    "\t\tif ((MK[Grayscale-1] * PK[k] - MK[k])*(MK[Grayscale-1] * PK[k] - MK[k]) / (PK[k] * (1 - PK[k])) > Var){\n",
    "\t\t\tVar = (MK[Grayscale-1] * PK[k] - MK[k])*(MK[Grayscale-1] * PK[k] - MK[k]) / (PK[k] * (1 - PK[k]));\n",
    "\t\t\tthresh = k;\n",
    "\t\t}\n",
    "\t}\n",
    " \n",
    "\t//阈值处理\n",
    "\tsrc.copyTo(dst);\n",
    "\tfor (int i = 0; i < r; ++i){\n",
    "\t    uchar* ptr = dst.ptr<uchar>(i);\n",
    "\t\tfor (int j = 0; j < c; ++j){\n",
    "\t\t\tif (ptr[j]> thresh)\n",
    "\t\t\t\tptr[j] = 255;\n",
    "\t\t\telse\n",
    "\t\t\t\tptr[j] = 0;\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn thresh;\n",
    "}\n",
    " \n",
    " \n",
    "int main(){\n",
    "\tcv::Mat src = cv::imread(\"I:\\\\Learning-and-Practice\\\\2019Change\\\\Image process algorithm\\\\Img\\\\Fig1039(a)(polymersomes).tif\");\n",
    "\tif (src.empty()){\n",
    "\t\treturn -1;\n",
    "\t}\n",
    "\tif (src.channels() > 1)\n",
    "\t\tcv::cvtColor(src, src, CV_RGB2GRAY);\n",
    " \n",
    "\tcv::Mat dst,dst2;\n",
    "\tint thresh=0;\n",
    "\tdouble t2 = (double)cv::getTickCount();\n",
    "\tthresh=Otsu(src , dst, thresh); //Otsu\n",
    "\tstd::cout << \"Mythresh=\" << thresh << std::endl;\n",
    "\tt2 = (double)cv::getTickCount() - t2;\n",
    "\tdouble time2 = (t2 *1000.) / ((double)cv::getTickFrequency());\n",
    "\tstd::cout << \"my_process=\" << time2 << \" ms. \" << std::endl << std::endl;\n",
    "    double  Otsu = 0;\n",
    " \n",
    "\tOtsu=cv::threshold(src, dst2, Otsu, 255, CV_THRESH_OTSU + CV_THRESH_BINARY);\n",
    "\tstd::cout << \"OpenCVthresh=\" << Otsu << std::endl;\n",
    " \n",
    "\tcv::namedWindow(\"src\", CV_WINDOW_NORMAL);\n",
    "\tcv::imshow(\"src\", src);\n",
    "\tcv::namedWindow(\"dst\", CV_WINDOW_NORMAL);\n",
    "\tcv::imshow(\"dst\", dst);\n",
    "\tcv::namedWindow(\"dst2\", CV_WINDOW_NORMAL);\n",
    "\tcv::imshow(\"dst2\", dst2);\n",
    "\t//cv::imwrite(\"I:\\\\Learning-and-Practice\\\\2019Change\\\\Image process algorithm\\\\Image Filtering\\\\MeanFilter\\\\TXT.jpg\",dst);\n",
    "\tcv::waitKey(0);\n",
    "}\n",
    "```\n",
    "\n",
    "* 2、自适应阈值\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <opencv2/core.hpp>\n",
    "#include <opencv2/highgui.hpp>\n",
    "#include <opencv2/imgproc.hpp>\n",
    " \n",
    "enum adaptiveMethod{meanFilter,gaaussianFilter,medianFilter};\n",
    " \n",
    "void AdaptiveThreshold(cv::Mat& src, cv::Mat& dst, double Maxval, int Subsize, double c, adaptiveMethod method = meanFilter){\n",
    " \n",
    "\tif (src.channels() > 1)\n",
    "\t\tcv::cvtColor(src, src, CV_RGB2GRAY);\n",
    " \n",
    "\tcv::Mat smooth;\n",
    "\tswitch (method)\n",
    "\t{\n",
    "\tcase  meanFilter:\n",
    "\t\tcv::blur(src, smooth, cv::Size(Subsize, Subsize));  //均值滤波\n",
    "\t\tbreak;\n",
    "\tcase gaaussianFilter:\n",
    "\t\tcv::GaussianBlur(src, smooth, cv::Size(Subsize, Subsize),0,0); //高斯滤波\n",
    "\t\tbreak;\n",
    "\tcase medianFilter:\n",
    "\t\tcv::medianBlur(src, smooth, Subsize);   //中值滤波\n",
    "\t\tbreak;\n",
    "\tdefault:\n",
    "\t\tbreak;\n",
    "\t}\n",
    " \n",
    "\tsmooth = smooth - c;\n",
    "\t\n",
    "\t//阈值处理\n",
    "\tsrc.copyTo(dst);\n",
    "\tfor (int r = 0; r < src.rows;++r){\n",
    "\t\tconst uchar* srcptr = src.ptr<uchar>(r);\n",
    "\t\tconst uchar* smoothptr = smooth.ptr<uchar>(r);\n",
    "\t\tuchar* dstptr = dst.ptr<uchar>(r);\n",
    "\t\tfor (int c = 0; c < src.cols; ++c){\n",
    "\t\t\tif (srcptr[c]>smoothptr[c]){\n",
    "\t\t\t\tdstptr[c] = Maxval;\n",
    "\t\t\t}\n",
    "\t\t\telse\n",
    "\t\t\t\tdstptr[c] = 0;\n",
    "\t\t}\n",
    "\t}\n",
    " \n",
    "}\n",
    " \n",
    "int main(){\n",
    "\tcv::Mat src = cv::imread(\"I:\\\\Learning-and-Practice\\\\2019Change\\\\Image process algorithm\\\\Img\\\\Fig1049(a)(spot_shaded_text_image).tif\");\n",
    "\tif (src.empty()){\n",
    "\t\treturn -1;\n",
    "\t}\n",
    "\tif (src.channels() > 1)\n",
    "\t\tcv::cvtColor(src, src, CV_RGB2GRAY);\n",
    " \n",
    "\tcv::Mat dst, dst2;\n",
    "\tdouble t2 = (double)cv::getTickCount();\n",
    "\tAdaptiveThreshold(src, dst, 255, 21, 10, meanFilter);  //\n",
    "\tt2 = (double)cv::getTickCount() - t2;\n",
    "\tdouble time2 = (t2 *1000.) / ((double)cv::getTickFrequency());\n",
    "\tstd::cout << \"my_process=\" << time2 << \" ms. \" << std::endl << std::endl;\n",
    " \n",
    " \n",
    "\tcv::adaptiveThreshold(src, dst2, 255, cv::ADAPTIVE_THRESH_MEAN_C, cv::THRESH_BINARY, 21, 10);\n",
    " \n",
    " \n",
    "\tcv::namedWindow(\"src\", CV_WINDOW_NORMAL);\n",
    "\tcv::imshow(\"src\", src);\n",
    "\tcv::namedWindow(\"dst\", CV_WINDOW_NORMAL);\n",
    "\tcv::imshow(\"dst\", dst);\n",
    "\tcv::namedWindow(\"dst2\", CV_WINDOW_NORMAL);\n",
    "\tcv::imshow(\"dst2\", dst2);\n",
    "\t//cv::imwrite(\"I:\\\\Learning-and-Practice\\\\2019Change\\\\Image process algorithm\\\\Image Filtering\\\\MeanFilter\\\\TXT.jpg\",dst);\n",
    "\tcv::waitKey(0);\n",
    "}\n",
    "```\n",
    "### 效果\n",
    "* 1、大津阈值\n",
    "\n",
    "![Image](https://img-blog.csdnimg.cn/2020041222365393.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDY0NzgxOQ==,size_16,color_FFFFFF,t_70)\n",
    "\n",
    "* 2、自适应阈值\n",
    "\n",
    "![Image](https://img-blog.csdnimg.cn/20200412223717279.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDY0NzgxOQ==,size_16,color_FFFFFF,t_70)\n",
    "\n",
    "###  相关技术文档、博客、教材、项目推荐\n",
    "opencv文档: [https://docs.opencv.org/3.1.0/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57](https://docs.opencv.org/3.1.0/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57)  \n",
    "博客：[https://blog.csdn.net/weixin_40647819/article/details/90179953](https://blog.csdn.net/weixin_40647819/article/details/90179953)  \n",
    "           [https://blog.csdn.net/weixin_40647819/article/details/90213858](https://blog.csdn.net/weixin_40647819/article/details/90213858)     \n",
    "python版本：[https://www.kancloud.cn/aollo/aolloopencv/267591](https://www.kancloud.cn/aollo/aolloopencv/267591)                    [http://www.woshicver.com/FifthSection/4_3_%E5%9B%BE%E5%83%8F%E9%98%88%E5%80%BC/ ](http://www.woshicver.com/FifthSection/4_3_%E5%9B%BE%E5%83%8F%E9%98%88%E5%80%BC/ )\n",
    "\n",
    "\n",
    "## 5.6 总结 \n",
    "\n",
    "该部分对两种经典阈值分割方法进行了介绍，读者可根据提供的资料进行学习，然后参考示例代码自行实现。Otsu的二值化有一些优化方法，读者可以尝试学习并实现。\n",
    "  \n",
    "---\n",
    "**Task05 阈值分割/二值化END.**\n",
    "\n",
    "--- ***By: 小武***\n",
    "\n",
    ">博客：[https://blog.csdn.net/weixin_40647819](https://blog.csdn.net/weixin_40647819)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
